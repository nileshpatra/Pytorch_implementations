{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import optim \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(64),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(64),\n",
    "                                      transforms.CenterCrop(64),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder('/home/nilesh/Desktop/MY FILES/hackathon-dataset/raw/apple_data/training', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder('/home/nilesh/Desktop/MY FILES/hackathon-dataset/raw/apple_data/testing', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size= 600 ,shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=30 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , (images , labels) = next(enumerate(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([600, 3, 64, 64]), torch.Size([600]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #64*64*3\n",
    "        self.conv1 = nn.Conv2d(3 , 32 , 3 , padding = 1)\n",
    "        #32*32*32\n",
    "        self.conv2 = nn.Conv2d(32 , 64 , 3 , padding = 1)\n",
    "        #16*16*64\n",
    "        self.conv3 = nn.Conv2d(64 , 32 , 3 , padding = 1)\n",
    "        #8*8*32\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(8*8*32 , 100)\n",
    "        self.fc2 = nn.Linear(100 , 64)\n",
    "        self.fc3 = nn.Linear(64 , 32)\n",
    "        self.fc4 = nn.Linear(32 , 4)\n",
    "        \n",
    "        \n",
    "    def forward(self , x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1 , 8*8*32)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x) , dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = neural_net()\n",
    "model(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dropout): Dropout(p=0.2)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters() , lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 :  1.3903584480285645\n",
      "epoch 2 :  1.4052120447158813\n",
      "epoch 3 :  1.4103714227676392\n",
      "epoch 4 :  1.3729112148284912\n",
      "epoch 5 :  1.3167728185653687\n",
      "epoch 6 :  2.406002998352051\n",
      "epoch 7 :  1.2771538496017456\n",
      "epoch 8 :  1.2908447980880737\n",
      "epoch 9 :  1.2527920007705688\n",
      "epoch 10 :  1.2339307069778442\n",
      "epoch 11 :  1.2202439308166504\n",
      "epoch 12 :  1.2000632286071777\n",
      "epoch 13 :  1.1535521745681763\n",
      "epoch 14 :  1.0538461208343506\n",
      "epoch 15 :  1.0827223062515259\n",
      "epoch 16 :  1.321999430656433\n",
      "epoch 17 :  1.388856291770935\n",
      "epoch 18 :  0.9144985675811768\n",
      "epoch 19 :  1.0560225248336792\n",
      "epoch 20 :  1.008840560913086\n",
      "epoch 21 :  1.0070688724517822\n",
      "epoch 22 :  1.0237065553665161\n",
      "epoch 23 :  1.038648009300232\n",
      "epoch 24 :  1.013755202293396\n",
      "epoch 25 :  1.0001152753829956\n",
      "epoch 26 :  0.9475778341293335\n",
      "epoch 27 :  0.9386507272720337\n",
      "epoch 28 :  0.8644523024559021\n",
      "epoch 29 :  0.8589496612548828\n",
      "epoch 30 :  0.7806224822998047\n",
      "epoch 31 :  0.7501751184463501\n",
      "epoch 32 :  0.7518090605735779\n",
      "epoch 33 :  0.7670373320579529\n",
      "epoch 34 :  0.7426868081092834\n",
      "epoch 35 :  0.6964324712753296\n",
      "epoch 36 :  0.6982243657112122\n",
      "epoch 37 :  0.6747198700904846\n",
      "epoch 38 :  0.6395437121391296\n",
      "epoch 39 :  0.64873206615448\n",
      "epoch 40 :  0.6169492602348328\n",
      "epoch 41 :  0.5953459739685059\n",
      "epoch 42 :  0.604027509689331\n",
      "epoch 43 :  0.5553878545761108\n",
      "epoch 44 :  0.522215723991394\n",
      "epoch 45 :  0.5325990915298462\n",
      "epoch 46 :  0.5305091738700867\n",
      "epoch 47 :  0.4811006784439087\n",
      "epoch 48 :  0.51493239402771\n",
      "epoch 49 :  0.513466477394104\n",
      "epoch 50 :  0.5726462006568909\n",
      "epoch 51 :  0.4823867380619049\n",
      "epoch 52 :  0.47525501251220703\n",
      "epoch 53 :  0.4351334273815155\n",
      "epoch 54 :  0.4130606949329376\n",
      "epoch 55 :  0.41158267855644226\n",
      "epoch 56 :  0.3990046977996826\n",
      "epoch 57 :  0.3369537591934204\n",
      "epoch 58 :  0.3764949142932892\n",
      "epoch 59 :  0.34369051456451416\n",
      "epoch 60 :  0.28931519389152527\n",
      "epoch 61 :  0.3151293396949768\n",
      "epoch 62 :  0.2879473567008972\n",
      "epoch 63 :  0.27850326895713806\n",
      "epoch 64 :  0.2605396807193756\n",
      "epoch 65 :  0.22387850284576416\n",
      "epoch 66 :  0.23441869020462036\n",
      "epoch 67 :  0.2148180603981018\n",
      "epoch 68 :  0.18912123143672943\n",
      "epoch 69 :  0.1708824336528778\n",
      "epoch 70 :  0.1631041318178177\n",
      "epoch 71 :  0.15264545381069183\n",
      "epoch 72 :  0.13226202130317688\n",
      "epoch 73 :  0.11526583135128021\n",
      "epoch 74 :  0.10054430365562439\n",
      "epoch 75 :  0.08460903912782669\n",
      "epoch 76 :  0.11133237183094025\n",
      "epoch 77 :  0.08969606459140778\n",
      "epoch 78 :  0.12361395359039307\n",
      "epoch 79 :  0.1540212333202362\n",
      "epoch 80 :  0.09040465950965881\n",
      "epoch 81 :  0.1192275881767273\n",
      "epoch 82 :  0.0991242527961731\n",
      "epoch 83 :  0.1532190591096878\n",
      "epoch 84 :  0.10861853510141373\n",
      "epoch 85 :  0.11217299103736877\n",
      "epoch 86 :  0.15286900103092194\n",
      "epoch 87 :  0.16112209856510162\n",
      "epoch 88 :  0.32292670011520386\n",
      "epoch 89 :  0.5724679827690125\n",
      "epoch 90 :  0.9485582709312439\n",
      "epoch 91 :  2.039637565612793\n",
      "epoch 92 :  1.2745455503463745\n",
      "epoch 93 :  0.7700189352035522\n",
      "epoch 94 :  0.7087751030921936\n",
      "epoch 95 :  0.7288700342178345\n",
      "epoch 96 :  0.6567276120185852\n",
      "epoch 97 :  0.6844968795776367\n",
      "epoch 98 :  0.6288868188858032\n",
      "epoch 99 :  0.6206818222999573\n",
      "epoch 100 :  0.6085394024848938\n",
      "epoch 101 :  0.5697891116142273\n",
      "epoch 102 :  0.535703718662262\n",
      "epoch 103 :  0.49245840311050415\n",
      "epoch 104 :  0.43638163805007935\n",
      "epoch 105 :  0.40831273794174194\n",
      "epoch 106 :  0.3407159149646759\n",
      "epoch 107 :  0.3311026394367218\n",
      "epoch 108 :  0.30207520723342896\n",
      "epoch 109 :  0.27256572246551514\n",
      "epoch 110 :  0.25579389929771423\n",
      "epoch 111 :  0.2178037464618683\n",
      "epoch 112 :  0.20097748935222626\n",
      "epoch 113 :  0.18522316217422485\n",
      "epoch 114 :  0.17705722153186798\n",
      "epoch 115 :  0.14406777918338776\n",
      "epoch 116 :  0.13461880385875702\n",
      "epoch 117 :  0.12055548280477524\n",
      "epoch 118 :  0.11744847893714905\n",
      "epoch 119 :  0.10014297813177109\n",
      "epoch 120 :  0.08987041562795639\n",
      "epoch 121 :  0.06954186409711838\n",
      "epoch 122 :  0.07074733078479767\n",
      "epoch 123 :  0.06273943930864334\n",
      "epoch 124 :  0.06298227608203888\n",
      "epoch 125 :  0.04851673170924187\n",
      "epoch 126 :  0.038606591522693634\n",
      "epoch 127 :  0.042496517300605774\n",
      "epoch 128 :  0.02872019074857235\n",
      "epoch 129 :  0.0283872801810503\n",
      "epoch 130 :  0.026961568742990494\n",
      "epoch 131 :  0.016481759026646614\n",
      "epoch 132 :  0.03260895237326622\n",
      "epoch 133 :  0.03875846415758133\n",
      "epoch 134 :  0.02126181684434414\n",
      "epoch 135 :  0.025890883058309555\n",
      "epoch 136 :  0.010877254419028759\n",
      "epoch 137 :  0.012164508923888206\n",
      "epoch 138 :  0.022880595177412033\n",
      "epoch 139 :  0.00802676472812891\n",
      "epoch 140 :  0.011486019007861614\n",
      "epoch 141 :  0.03647244721651077\n",
      "epoch 142 :  0.05493767932057381\n",
      "epoch 143 :  0.05904427170753479\n",
      "epoch 144 :  0.008433870039880276\n",
      "epoch 145 :  0.08910543471574783\n",
      "epoch 146 :  0.015550713986158371\n",
      "epoch 147 :  0.14045710861682892\n",
      "epoch 148 :  0.013927869498729706\n",
      "epoch 149 :  0.03660949319601059\n",
      "epoch 150 :  0.03262768313288689\n",
      "epoch 151 :  0.03156683221459389\n",
      "epoch 152 :  0.046453580260276794\n",
      "epoch 153 :  0.020739618688821793\n",
      "epoch 154 :  0.01082813460379839\n",
      "epoch 155 :  0.009914749301970005\n",
      "epoch 156 :  0.00826825201511383\n",
      "epoch 157 :  0.014824354089796543\n",
      "epoch 158 :  0.01883052848279476\n",
      "epoch 159 :  0.018326550722122192\n",
      "epoch 160 :  0.008728045970201492\n",
      "epoch 161 :  0.0077166431583464146\n",
      "epoch 162 :  0.010905062779784203\n",
      "epoch 163 :  0.009160510264337063\n",
      "epoch 164 :  0.010011649690568447\n",
      "epoch 165 :  0.004386375658214092\n",
      "epoch 166 :  0.008147088810801506\n",
      "epoch 167 :  0.009066578932106495\n",
      "epoch 168 :  0.006621886044740677\n",
      "epoch 169 :  0.002870316617190838\n",
      "epoch 170 :  0.010146436281502247\n",
      "epoch 171 :  0.0028387093916535378\n",
      "epoch 172 :  0.009373500943183899\n",
      "epoch 173 :  0.0017537069506943226\n",
      "epoch 174 :  0.0027667530812323093\n",
      "epoch 175 :  0.00350663298740983\n",
      "epoch 176 :  0.0012657023034989834\n",
      "epoch 177 :  0.0016674470389261842\n",
      "epoch 178 :  0.0051189628429710865\n",
      "epoch 179 :  0.0008554685045965016\n",
      "epoch 180 :  0.0015210810815915465\n",
      "epoch 181 :  0.0017686617793515325\n",
      "epoch 182 :  0.0019400895107537508\n",
      "epoch 183 :  0.0027585597708821297\n",
      "epoch 184 :  0.002198389731347561\n",
      "epoch 185 :  0.004710136912763119\n",
      "epoch 186 :  0.0011896538781002164\n",
      "epoch 187 :  0.013915561139583588\n",
      "epoch 188 :  0.002152856905013323\n",
      "epoch 189 :  0.0009124744101427495\n",
      "epoch 190 :  0.004823616240173578\n",
      "epoch 191 :  0.0014745887601748109\n",
      "epoch 192 :  0.006913213059306145\n",
      "epoch 193 :  0.0006827640463598073\n",
      "epoch 194 :  0.000922346138395369\n",
      "epoch 195 :  0.0008979952544905245\n",
      "epoch 196 :  0.0003755068755708635\n",
      "epoch 197 :  0.00048094510566443205\n",
      "epoch 198 :  0.0003295389760751277\n",
      "epoch 199 :  0.0015970634995028377\n",
      "epoch 200 :  0.0011614218819886446\n",
      "epoch 201 :  0.0013052892172709107\n",
      "epoch 202 :  0.0008779811905696988\n",
      "epoch 203 :  0.004363559652119875\n",
      "epoch 204 :  0.0005565420724451542\n",
      "epoch 205 :  0.0047159879468381405\n",
      "epoch 206 :  0.0007429131073877215\n",
      "epoch 207 :  0.0008156490512192249\n",
      "epoch 208 :  0.011845874600112438\n",
      "epoch 209 :  0.0011359993368387222\n",
      "epoch 210 :  0.008666101843118668\n",
      "epoch 211 :  0.0183380376547575\n",
      "epoch 212 :  0.0004509568098001182\n",
      "epoch 213 :  0.01706422120332718\n",
      "epoch 214 :  0.000967387342825532\n",
      "epoch 215 :  0.004681733436882496\n",
      "epoch 216 :  0.007634684909135103\n",
      "epoch 217 :  0.018949395045638084\n",
      "epoch 218 :  0.007680501323193312\n",
      "epoch 219 :  0.0010731900110840797\n",
      "epoch 220 :  0.0033821891993284225\n",
      "epoch 221 :  0.0023394569288939238\n",
      "epoch 222 :  0.03233436122536659\n",
      "epoch 223 :  0.001863981131464243\n",
      "epoch 224 :  0.0020275027491152287\n",
      "epoch 225 :  0.00215123500674963\n",
      "epoch 226 :  0.0038244971074163914\n",
      "epoch 227 :  0.020441506057977676\n",
      "epoch 228 :  0.023296337574720383\n",
      "epoch 229 :  0.0017482551047578454\n",
      "epoch 230 :  0.0015606983797624707\n",
      "epoch 231 :  0.0038130616303533316\n",
      "epoch 232 :  0.03909881412982941\n",
      "epoch 233 :  0.006448149681091309\n",
      "epoch 234 :  0.0028643286786973476\n",
      "epoch 235 :  0.0036302690859884024\n",
      "epoch 236 :  0.01098747830837965\n",
      "epoch 237 :  0.003321809461340308\n",
      "epoch 238 :  0.0008045927970670164\n",
      "epoch 239 :  0.0007621152908541262\n",
      "epoch 240 :  0.00960750225931406\n",
      "epoch 241 :  0.0017185267060995102\n",
      "epoch 242 :  0.002602305728942156\n",
      "epoch 243 :  0.0014162345323711634\n",
      "epoch 244 :  0.0029834385495632887\n",
      "epoch 245 :  0.004962951876223087\n",
      "epoch 246 :  0.007997129112482071\n",
      "epoch 247 :  0.008280535228550434\n",
      "epoch 248 :  0.0012328728334978223\n",
      "epoch 249 :  0.0009584482759237289\n",
      "epoch 250 :  0.007419457659125328\n",
      "epoch 251 :  0.0012594739673659205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 252 :  0.0009131181286647916\n",
      "epoch 253 :  0.0028461976908147335\n",
      "epoch 254 :  0.0013656584778800607\n",
      "epoch 255 :  0.0018028473714366555\n",
      "epoch 256 :  0.001033708220347762\n",
      "epoch 257 :  0.002522779628634453\n",
      "epoch 258 :  0.0036107730120420456\n",
      "epoch 259 :  0.01569407433271408\n",
      "epoch 260 :  0.0005337190814316273\n",
      "epoch 261 :  0.015370087698101997\n",
      "epoch 262 :  0.017603019252419472\n",
      "epoch 263 :  0.006113184150308371\n",
      "epoch 264 :  0.0011318882461637259\n",
      "epoch 265 :  0.006473087705671787\n",
      "epoch 266 :  0.016775496304035187\n",
      "epoch 267 :  0.000766850309446454\n",
      "epoch 268 :  0.0005100623820908368\n",
      "epoch 269 :  0.003970366902649403\n",
      "epoch 270 :  0.11490260809659958\n",
      "epoch 271 :  0.0007948168204165995\n",
      "epoch 272 :  0.01266928855329752\n",
      "epoch 273 :  0.06929776817560196\n",
      "epoch 274 :  0.032360587269067764\n",
      "epoch 275 :  0.014176413416862488\n",
      "epoch 276 :  0.03510502353310585\n",
      "epoch 277 :  0.02936345338821411\n",
      "epoch 278 :  0.013489956967532635\n",
      "epoch 279 :  0.005708457436412573\n",
      "epoch 280 :  0.010232516564428806\n",
      "epoch 281 :  0.01110859401524067\n",
      "epoch 282 :  0.008439996279776096\n",
      "epoch 283 :  0.019317537546157837\n",
      "epoch 284 :  0.009542002342641354\n",
      "epoch 285 :  0.020829375833272934\n",
      "epoch 286 :  0.012361629866063595\n",
      "epoch 287 :  0.0012794220820069313\n",
      "epoch 288 :  0.0031503411009907722\n",
      "epoch 289 :  0.004815795458853245\n",
      "epoch 290 :  0.0034860149025917053\n",
      "epoch 291 :  0.008912735618650913\n",
      "epoch 292 :  0.01718938909471035\n",
      "epoch 293 :  0.005324282683432102\n",
      "epoch 294 :  0.007380913011729717\n",
      "epoch 295 :  0.0020742607302963734\n",
      "epoch 296 :  0.015197456814348698\n",
      "epoch 297 :  0.003791181603446603\n",
      "epoch 298 :  0.0025549165438860655\n",
      "epoch 299 :  0.0030372433830052614\n",
      "epoch 300 :  0.0031740220729261637\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(images)\n",
    "    loss = criterion(output , labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch' , epoch+1 , ': ' ,loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = torch.exp(model(images)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_predictions = []\n",
    "for pred in train_predictions:\n",
    "    final_train_predictions.append(pred.argmax())\n",
    "final_train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy : ' , (final_train_predictions == labels.detach().numpy()).sum()/len(final_train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , (test_img , test_label) = next(enumerate(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 3, 2, 0, 1, 1, 2, 3, 0, 0, 3, 1, 2, 2, 0, 2, 0, 3, 1, 2, 1, 0, 1,\n",
       "        2, 2, 3, 0, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.exp(model(test_img)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = []\n",
    "for pred in prediction:\n",
    "    final_predictions.append(pred.argmax())\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test predictions :  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print('test predictions : ' , (final_predictions == test_label.detach().numpy()).sum()/len(final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model1.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model , open(filename , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename ,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dropout): Dropout(p=0.2)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.exp(loaded_model(test_img)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = []\n",
    "for pr in pred:\n",
    "    final_predictions.append(pr.argmax())\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 3, 2, 0, 1, 1, 2, 3, 0, 0, 3, 1, 2, 2, 0, 2, 0, 3, 1, 2, 1, 0, 1,\n",
       "        2, 2, 3, 0, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_predictions == test_label.detach().numpy()).sum()/len(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['healthy', 'rot', 'rust', 'scab'],\n",
       " {'healthy': 0, 'rot': 1, 'rust': 2, 'scab': 3})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_classes('/home/nilesh/Desktop/MY FILES/hackathon-dataset/raw/apple_data/training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
