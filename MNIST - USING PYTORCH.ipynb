{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets , transforms\n",
    "transform = transforms.Compose([transforms.ToTensor() , transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('MNIST_data/' , download = True , train = True , transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset , batch_size = 64 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('MNIST_data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                             ])),\n",
    "   batch_size = 64,shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('MNIST_data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                             ])),\n",
    "   batch_size = 1000 , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = enumerate(train_loader)\n",
    "batch_idx, (images , labels) = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.8352941 , -0.42745095, -0.42745095,\n",
       "         0.17647064,  0.9843137 ,  1.        ,  0.9843137 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9843137 ,  1.        ,  0.9843137 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9843137 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -0.8352941 ,\n",
       "         0.12941182,  0.12941182,  0.3803922 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.96862745, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -0.30196077,  0.7019608 ,  0.73333335,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.96862745, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        ,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.47450984,  0.11372554,\n",
       "         0.11372554,  0.11372554,  0.12156868,  0.11372554,  0.11372554,\n",
       "         0.11372554,  0.11372554,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.35686278, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        ,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.96862745,  0.96862745, -0.4352941 , -0.7647059 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.0196079 ,  0.9843137 ,  0.96862745,  0.96862745,\n",
       "         0.35686278, -0.84313726, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -0.58431375,  0.41176474,  0.20784318,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.1372549 ,  0.9843137 ,  1.        ,  0.9843137 ,  0.69411767,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.14509803,  0.96862745,  0.9843137 ,  0.96862745,  0.6862745 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.7490196 ,\n",
       "         0.8117647 ,  0.96862745,  0.9843137 ,  0.96862745, -0.5294118 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.09803921,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.47450984, -0.84313726,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ,  0.7019608 ,\n",
       "         0.96862745,  0.96862745,  0.9843137 , -0.1607843 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ,  0.70980394,\n",
       "         0.9843137 ,  0.9843137 ,  1.        , -0.15294117, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ,  0.7019608 ,\n",
       "         0.96862745,  0.96862745,  0.9843137 , -0.1607843 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ,  0.4901961 ,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.00392163, -0.9607843 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.70980394,\n",
       "         0.96862745,  0.96862745,  0.9843137 ,  0.96862745, -0.7254902 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.9137255 ,\n",
       "         0.16078436,  0.96862745,  0.9843137 ,  0.96862745, -0.7254902 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.1372549 ,  0.9843137 ,  1.        ,  0.9843137 , -0.31764704,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.14509803,  0.96862745,  0.9843137 ,  0.96862745,  0.6862745 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.88235295, -0.7254902 ,  0.78039217,  0.96862745,  0.6862745 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.67058825,  0.60784316,  0.6862745 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.6784314 , -0.52156866,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[1].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3724b77b38>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().reshape(28,28) , cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating neural network\n",
    "n_input = 784\n",
    "n_hidden = 256\n",
    "n_output = 10\n",
    "\n",
    "wh = torch.randn(n_input , n_hidden)\n",
    "wo = torch.randn(n_hidden , n_output)\n",
    "\n",
    "bh = torch.randn(1 , n_hidden)\n",
    "bo = torch.randn(1 , n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(z):\n",
    "    return 1/(1 + torch.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = images.view(images.shape[0] , -1)\n",
    "#-1 sees and puts appropriate number of elements into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_output = activation(torch.mm(flattened , wh) + bh)\n",
    "outputs = torch.mm(hidden_output , wo) + bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 9.9528e-01, 9.8606e-05, 2.7520e-06, 1.0000e+00, 1.4682e-04,\n",
       "        9.9997e-01, 1.3182e-06, 8.7700e-01, 1.6161e-03])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]\n",
    "# we should instead be using doftmax since its a multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    return torch.exp(-z)/torch.sum(torch.exp(-z) , dim=1).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(outputs).sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(n_input , n_hidden)\n",
    "        self.output = nn.Linear(n_hidden , n_output)\n",
    "        \n",
    "    def forward(self , x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.output(x) , dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Neural_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neural_net(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class robust_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784 , 128)\n",
    "        self.hidden2 = nn.Linear(128 , 64)\n",
    "        self.output = nn.Linear(64 , 10)\n",
    "\n",
    "    def forward(self , x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.softmax(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "robust_nn(\n",
       "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = robust_nn()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdaptiveAvgPool1d',\n",
       " 'AdaptiveAvgPool2d',\n",
       " 'AdaptiveAvgPool3d',\n",
       " 'AdaptiveLogSoftmaxWithLoss',\n",
       " 'AdaptiveMaxPool1d',\n",
       " 'AdaptiveMaxPool2d',\n",
       " 'AdaptiveMaxPool3d',\n",
       " 'AlphaDropout',\n",
       " 'AvgPool1d',\n",
       " 'AvgPool2d',\n",
       " 'AvgPool3d',\n",
       " 'BCELoss',\n",
       " 'BCEWithLogitsLoss',\n",
       " 'BatchNorm1d',\n",
       " 'BatchNorm2d',\n",
       " 'BatchNorm3d',\n",
       " 'Bilinear',\n",
       " 'CELU',\n",
       " 'CTCLoss',\n",
       " 'ConstantPad1d',\n",
       " 'ConstantPad2d',\n",
       " 'ConstantPad3d',\n",
       " 'Container',\n",
       " 'Conv1d',\n",
       " 'Conv2d',\n",
       " 'Conv3d',\n",
       " 'ConvTranspose1d',\n",
       " 'ConvTranspose2d',\n",
       " 'ConvTranspose3d',\n",
       " 'CosineEmbeddingLoss',\n",
       " 'CosineSimilarity',\n",
       " 'CrossEntropyLoss',\n",
       " 'CrossMapLRN2d',\n",
       " 'DataParallel',\n",
       " 'Dropout',\n",
       " 'Dropout2d',\n",
       " 'Dropout3d',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'EmbeddingBag',\n",
       " 'FeatureAlphaDropout',\n",
       " 'Fold',\n",
       " 'FractionalMaxPool2d',\n",
       " 'GLU',\n",
       " 'GRU',\n",
       " 'GRUCell',\n",
       " 'GroupNorm',\n",
       " 'Hardshrink',\n",
       " 'Hardtanh',\n",
       " 'HingeEmbeddingLoss',\n",
       " 'InstanceNorm1d',\n",
       " 'InstanceNorm2d',\n",
       " 'InstanceNorm3d',\n",
       " 'KLDivLoss',\n",
       " 'L1Loss',\n",
       " 'LPPool1d',\n",
       " 'LPPool2d',\n",
       " 'LSTM',\n",
       " 'LSTMCell',\n",
       " 'LayerNorm',\n",
       " 'LeakyReLU',\n",
       " 'Linear',\n",
       " 'LocalResponseNorm',\n",
       " 'LogSigmoid',\n",
       " 'LogSoftmax',\n",
       " 'MSELoss',\n",
       " 'MarginRankingLoss',\n",
       " 'MaxPool1d',\n",
       " 'MaxPool2d',\n",
       " 'MaxPool3d',\n",
       " 'MaxUnpool1d',\n",
       " 'MaxUnpool2d',\n",
       " 'MaxUnpool3d',\n",
       " 'Module',\n",
       " 'ModuleDict',\n",
       " 'ModuleList',\n",
       " 'MultiLabelMarginLoss',\n",
       " 'MultiLabelSoftMarginLoss',\n",
       " 'MultiMarginLoss',\n",
       " 'NLLLoss',\n",
       " 'NLLLoss2d',\n",
       " 'PReLU',\n",
       " 'PairwiseDistance',\n",
       " 'Parameter',\n",
       " 'ParameterDict',\n",
       " 'ParameterList',\n",
       " 'PixelShuffle',\n",
       " 'PoissonNLLLoss',\n",
       " 'RNN',\n",
       " 'RNNBase',\n",
       " 'RNNCell',\n",
       " 'RNNCellBase',\n",
       " 'RReLU',\n",
       " 'ReLU',\n",
       " 'ReLU6',\n",
       " 'ReflectionPad1d',\n",
       " 'ReflectionPad2d',\n",
       " 'ReplicationPad1d',\n",
       " 'ReplicationPad2d',\n",
       " 'ReplicationPad3d',\n",
       " 'SELU',\n",
       " 'Sequential',\n",
       " 'Sigmoid',\n",
       " 'SmoothL1Loss',\n",
       " 'SoftMarginLoss',\n",
       " 'Softmax',\n",
       " 'Softmax2d',\n",
       " 'Softmin',\n",
       " 'Softplus',\n",
       " 'Softshrink',\n",
       " 'Softsign',\n",
       " 'Tanh',\n",
       " 'Tanhshrink',\n",
       " 'Threshold',\n",
       " 'TripletMarginLoss',\n",
       " 'Unfold',\n",
       " 'Upsample',\n",
       " 'UpsamplingBilinear2d',\n",
       " 'UpsamplingNearest2d',\n",
       " 'ZeroPad2d',\n",
       " '_VF',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functions',\n",
       " '_reduction',\n",
       " 'backends',\n",
       " 'functional',\n",
       " 'grad',\n",
       " 'init',\n",
       " 'modules',\n",
       " 'parallel',\n",
       " 'parameter',\n",
       " 'utils']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.nn\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3010, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 10]), torch.Size([64]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784 , 128) , nn.ReLU() , \n",
    "                     nn.Linear(128 , 64) , nn.ReLU() , \n",
    "                     nn.Linear(64 , 10) , nn.Softmax(dim=1))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logits = model(flattened)\n",
    "loss = criterion(logits , labels)\n",
    "print(loss)\n",
    "logits.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0963, 1.0643],\n",
      "        [0.0030, 0.0011]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2 , 2 , requires_grad = True)\n",
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PowBackward0 at 0x7f3724c43be0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1551, -0.5158],\n",
       "         [-0.0272,  0.0166]]), tensor([[ 0.1551, -0.5158],\n",
       "         [-0.0272,  0.0166]], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad , x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before back propagation  None\n",
      "after back propagation tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.8207e-04, -2.8207e-04, -2.8207e-04,  ..., -2.8207e-04,\n",
      "         -2.8207e-04, -2.8207e-04],\n",
      "        [-6.6660e-06, -6.6660e-06, -6.6660e-06,  ..., -6.6660e-06,\n",
      "         -6.6660e-06, -6.6660e-06],\n",
      "        ...,\n",
      "        [ 5.5464e-06,  5.5464e-06,  5.5464e-06,  ...,  5.5464e-06,\n",
      "          5.5464e-06,  5.5464e-06],\n",
      "        [ 5.3688e-05,  5.3688e-05,  5.3688e-05,  ...,  5.3688e-05,\n",
      "          5.3688e-05,  5.3688e-05],\n",
      "        [-7.7261e-05, -7.7261e-05, -7.7261e-05,  ..., -7.7261e-05,\n",
      "         -7.7261e-05, -7.7261e-05]])\n"
     ]
    }
   ],
   "source": [
    "print('before back propagation ' , model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('after back propagation' , model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'Optimizer',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'lr_scheduler']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters() , lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.8207e-04, -2.8207e-04, -2.8207e-04,  ..., -2.8207e-04,\n",
      "         -2.8207e-04, -2.8207e-04],\n",
      "        [-6.6660e-06, -6.6660e-06, -6.6660e-06,  ..., -6.6660e-06,\n",
      "         -6.6660e-06, -6.6660e-06],\n",
      "        ...,\n",
      "        [ 5.5464e-06,  5.5464e-06,  5.5464e-06,  ...,  5.5464e-06,\n",
      "          5.5464e-06,  5.5464e-06],\n",
      "        [ 5.3688e-05,  5.3688e-05,  5.3688e-05,  ...,  5.3688e-05,\n",
      "          5.3688e-05,  5.3688e-05],\n",
      "        [-7.7261e-05, -7.7261e-05, -7.7261e-05,  ..., -7.7261e-05,\n",
      "         -7.7261e-05, -7.7261e-05]])\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "output = model(flattened)\n",
    "loss = criterion(output , labels)\n",
    "loss.backward()\n",
    "print(model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-2.8207e-04, -2.8207e-04, -2.8207e-04,  ..., -2.8207e-04,\n",
       "         -2.8207e-04, -2.8207e-04],\n",
       "        [-6.6660e-06, -6.6660e-06, -6.6660e-06,  ..., -6.6660e-06,\n",
       "         -6.6660e-06, -6.6660e-06],\n",
       "        ...,\n",
       "        [ 5.5464e-06,  5.5464e-06,  5.5464e-06,  ...,  5.5464e-06,\n",
       "          5.5464e-06,  5.5464e-06],\n",
       "        [ 5.3688e-05,  5.3688e-05,  5.3688e-05,  ...,  5.3688e-05,\n",
       "          5.3688e-05,  5.3688e-05],\n",
       "        [-7.7261e-05, -7.7261e-05, -7.7261e-05,  ..., -7.7261e-05,\n",
       "         -7.7261e-05, -7.7261e-05]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.step()\n",
    "model[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 :  147.2189404964447\n",
      "epoch  2 :  147.2189404964447\n",
      "epoch  3 :  147.2189404964447\n",
      "epoch  4 :  147.2189404964447\n",
      "epoch  5 :  147.2189404964447\n",
      "epoch  6 :  147.2189404964447\n",
      "epoch  7 :  147.2189404964447\n",
      "epoch  8 :  147.2189404964447\n",
      "epoch  9 :  147.2189404964447\n",
      "epoch  10 :  147.2189404964447\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    run_loss = 0\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "        image = image.view(1 , 784)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(image)\n",
    "        loss = criterion(output , label.view(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        run_loss += loss.item()\n",
    "    print('epoch ' , epoch+1 , ': ' , run_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 :  2.3002965450286865\n",
      "epoch  2 :  2.3002965450286865\n",
      "epoch  3 :  2.3002965450286865\n",
      "epoch  4 :  2.3002965450286865\n",
      "epoch  5 :  2.3002965450286865\n",
      "epoch  6 :  2.3002965450286865\n",
      "epoch  7 :  2.3002965450286865\n",
      "epoch  8 :  2.3002965450286865\n",
      "epoch  9 :  2.3002965450286865\n",
      "epoch  10 :  2.3002965450286865\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    image = images.view(images.shape[0] , -1)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model.forward(image)\n",
    "    loss = criterion(output , labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch ' , epoch+1 , ': ' , loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
